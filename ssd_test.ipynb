{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "# from datasets import fishes\n",
    "from datasets import dataset_factory\n",
    "from preprocessing import preprocessing_factory\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# take an array of shape (n, height, width) or (n, height, width, channels)\n",
    "# and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\n",
    "def vis_square(data, padsize=1, padval=0):\n",
    "    data -= data.min()\n",
    "    data /= data.max()\n",
    "    \n",
    "    # force the number of filters to be square\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
    "    \n",
    "    # tile the filters into an image\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    \n",
    "    plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "ssd_shape = [500, 500]\n",
    "preprocessing_name = \"ssd_inception\"\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    dataset = dataset_factory.get_dataset(\n",
    "                \"fishes\", \"validation\", \"tmp/fish/dataset\")\n",
    "    num_readers = 5\n",
    "    batch_size = 4\n",
    "    provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "                        dataset,\n",
    "                        num_readers=num_readers,\n",
    "                        common_queue_capacity=20 * batch_size,\n",
    "                        common_queue_min=10 * batch_size,\n",
    "                        shuffle=True)\n",
    "    image, label, bboxes, name = provider.get(['image', 'object/label', 'object/bbox', 'name'])\n",
    "    image_preprocessing_fn = preprocessing_factory.get_preprocessing(\n",
    "            preprocessing_name, is_training=True)\n",
    "    image, label, bboxes = image_preprocessing_fn(image, label, bboxes, ssd_shape)\n",
    "    images, labels, bboxes = tf.train.batch(\n",
    "          [image, label, bboxes],\n",
    "          batch_size=batch_size,\n",
    "          num_threads=1,\n",
    "          capacity=2 * batch_size,\n",
    "          dynamic_pad=True)\n",
    "    with tf.Session() as sess:\n",
    "        with slim.queues.QueueRunners(sess):\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            np_images, np_bboxes, labels = sess.run([images, bboxes, labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def vis_imgae_bbox(np_images, np_bboxes):\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "    plt.rcParams['figure.figsize'] = (5, 5)\n",
    "    ind = 0\n",
    "    height, width = np_images[ind].shape[0:2]\n",
    "\n",
    "    for ind in range(len(np_images)):\n",
    "        plt.figure()\n",
    "        plt.imshow(np_images[ind].astype(np.uint8))\n",
    "        currentAxis = plt.gca()\n",
    "        j = 3\n",
    "        for rect in np_bboxes[ind]:\n",
    "            [ymin, xmin, ymax, xmax] = rect\n",
    "            coords = (xmin*width, ymin*height), (xmax-xmin)*width, (ymax-ymin)*height\n",
    "            currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=colors[j], linewidth=2))\n",
    "            j += 1\n",
    "\n",
    "# vis_imgae_bbox(np_images, np_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inception_v3\n",
    "\n",
    "import os\n",
    "\n",
    "from nets import inception\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "ssd_shape = [450, 450]\n",
    "preprocessing_name = \"ssd_inception\"\n",
    "\n",
    "\n",
    "def get_init_fn():\n",
    "    \"\"\"Returns a function run by the chief worker to warm-start the training.\"\"\"\n",
    "    checkpoint_exclude_scopes=[\"InceptionV3/Logits\", \"InceptionV3/AuxLogits\"]\n",
    "    \n",
    "    exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "\n",
    "    variables_to_restore = []\n",
    "    for var in slim.get_model_variables():\n",
    "        excluded = False\n",
    "        for exclusion in exclusions:\n",
    "            if var.op.name.startswith(exclusion):\n",
    "                excluded = True\n",
    "                break\n",
    "        if not excluded:\n",
    "            variables_to_restore.append(var)\n",
    "    \n",
    "    return slim.assign_from_checkpoint_fn(\n",
    "        os.path.join(checkpoints_dir, 'inception_v3.ckpt'),\n",
    "        variables_to_restore)\n",
    "\n",
    "\n",
    "train_dir = 'tmp/fish/inception_ssd/'\n",
    "fish_data_dir = 'tmp/fish/dataset/'\n",
    "checkpoints_dir = 'tmp/fish/my_checkpoints/'\n",
    "batch_size = 8\n",
    "with tf.Graph().as_default():\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    dataset = dataset_factory.get_dataset(\n",
    "                \"fishes\", \"validation\", \"tmp/fish/dataset\")\n",
    "    \n",
    "    provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "                        dataset,\n",
    "                        num_readers=num_readers,\n",
    "                        common_queue_capacity=20 * batch_size,\n",
    "                        common_queue_min=10 * batch_size,\n",
    "                        shuffle=True)\n",
    "    image_raw, label, bboxes, name = provider.get(['image', 'object/label', 'object/bbox', 'name'])\n",
    "    image_preprocessing_fn = preprocessing_factory.get_preprocessing(\n",
    "            preprocessing_name, is_training=True)\n",
    "    image, label, bboxes = image_preprocessing_fn(image_raw, label, bboxes, ssd_shape)\n",
    "    image_raw, images, labels, bboxes = tf.train.batch(\n",
    "          [image_raw, image, label, bboxes],\n",
    "          batch_size=batch_size,\n",
    "          num_threads=1,\n",
    "          capacity=2 * batch_size,\n",
    "          dynamic_pad=True)\n",
    "    \n",
    "    # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        _, _end_points = inception.inception_v3_base(images)\n",
    "        \n",
    "#     checkpoint_path = tf.train.latest_checkpoint(train_dir)\n",
    "    checkpoint_path = os.path.join(checkpoints_dir, 'inception_v3.ckpt')\n",
    "    init_fn = slim.assign_from_checkpoint_fn(checkpoint_path, slim.get_variables_to_restore())   \n",
    "    with tf.Session() as sess:\n",
    "        with slim.queues.QueueRunners(sess):\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            init_fn(sess)\n",
    "            np_end_points, np_images, np_bboxes = sess.run([_end_points, images, bboxes])\n",
    "            plt.rcParams['figure.figsize'] = (30.0, 15.0)\n",
    "#             for i in range(batch_size): \n",
    "#                 _image = np_images[i, :, :, :]\n",
    "#                 convnet = np_end_points['Mixed_5c'][i]\n",
    "#                 vis_square(convnet.transpose(2, 0, 1), padval=0.5)\n",
    "\n",
    "#                 plt.figure()\n",
    "#                 plt.imshow(_image.astype(np.uint8))\n",
    "#                 plt.axis('off')\n",
    "#                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "width, height = ssd_shape\n",
    "for i in range(batch_size): \n",
    "    _image = np_images[i, :, :, :]\n",
    "    convnet = np_end_points['Mixed_6e'][i]\n",
    "    vis_square(convnet.transpose(2, 0, 1), padval=0.5)\n",
    "\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "    plt.figure()\n",
    "    plt.imshow(_image.astype(np.uint8))\n",
    "    currentAxis = plt.gca()\n",
    "    j = 3\n",
    "    for rect in np_bboxes[i]:\n",
    "        [ymin, xmin, ymax, xmax] = rect\n",
    "        coords = (xmin*width, ymin*height), (xmax-xmin)*width, (ymax-ymin)*height\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=colors[j], linewidth=2))\n",
    "        j += 1\n",
    "#     plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_end_points['Mixed_7c'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
